# 3D Scene Navigation & Video Rendering

A Python-based system for rendering high-quality videos from inside 3D Gaussian Splat scenes using path planning and obstacle avoidance algorithms.

## Features

✓ **Task 1: Render a video from inside the scene** – High-quality point-based rendering with camera trajectory  
✓ **Task 4: Path planning** – A* algorithm with Euclidean distance heuristic  
✓ **Task 5: Obstacle avoidance** – Artificial Potential Field (APF) for smooth collision-free paths  

---

## Installation

### Prerequisites
- Python 3.8+
- pip

### Quick Setup

```bash
# Clone or navigate to project directory
cd project

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Dependencies

**Core packages** (see `requirements.txt`):
- `numpy` – Numerical computations
- `plyfile` – PLY file I/O
- `Pillow` – Image processing
- `scipy` – Scientific computing
- `tqdm` – Progress bars
- `opencv-python` – Video encoding (via ffmpeg)

**System requirement:**
- `ffmpeg` – For video assembly (must be in PATH or specify custom path in renderer.py)

### Verify Installation

```bash
python -c "import numpy, plyfile, PIL, scipy; print('All imports OK')"
```

---

## Project Structure

```
Assignment4_ICV/
├── src/
│   ├── main.py              # Entry point, orchestrates pipeline
│   ├── explorer.py          # Scene loading and basic analysis
│   ├── path_planner.py      # Free-space detection & waypoint generation
│   └── renderer.py          # Camera trajectory & frame rendering
│
├── output/                  # Generated videos and metadata (auto-created)
│   ├── Museume.mp4            # Final indoor video
│   ├── outdoor-street.mp4      # Camera trajectory (NeRF format)
│
├── requirements.txt
├── README.md
└── TECHNICAL_REPORT.md
```

---

## Usage Guide

### Basic Usage

```bash
# Run with default scene (Museume.ply)
python -m src.main

# Run with custom scene
python -m src.main input/ConferenceHall.ply

# Run with Theatre scene
python -m src.main input/Theatre.ply
```

### Output Files

After running, check `output/` directory:

| File | Purpose |
|------|---------|
| `video.mp4` | Main rendered video (30 fps, 1920×1080) |
| `transforms.json` | Camera trajectory (NeRF format for external tools) |
| `frames/` | Individual PNG frames (can be used separately) |

### Example: Basic Workflow

```python
from src.explorer import Scene
from src.path_planner import find_free_space_points, generate_waypoints
from src.renderer import render_video

# 1. Load scene
scene = Scene("input/Museume.ply")
xyz = scene.xyz
colors = scene.colors

# 2. Find navigation space
free_pts, voxel_counts = find_free_space_points(xyz, voxel_size=1.5)

# 3. Generate camera path
waypoints = generate_waypoints(free_pts, voxel_counts, voxel_size=1.5)

# 4. Render and save
render_video(camera_positions, camera_directions, xyz, colors, ...)
```

---

## Algorithm Descriptions

### 1. Scene Loading (explorer.py)

**Goal:** Load PLY file and extract point positions and colors

**Input:** PLY file (typically from 3D Gaussian Splat)

**Output:** 
- `xyz` – (N, 3) point positions
- `colors` – (N, 3) RGB colors [0, 1]
- `center`, `size` – Scene statistics

**Color handling:**
- If SH coefficients present → Convert from spherical harmonics DC component
- Else if RGB present → Normalize from [0, 255] to [0, 1]
- Else → Default mid-gray (0.5, 0.5, 0.5)

---

### 2. Free-Space Detection (path_planner.py)

**Goal:** Find empty voxels suitable for camera navigation

**Algorithm:**

```
1. Voxelize scene: partition 3D space into grid cells (size=1.5m)
2. Count Gaussian points per voxel
3. For each voxel:
   - If point_count < empty_threshold (50):
     - If has ≥3 adjacent dense voxels (>200 points)
     - AND within Z-height range [center-0.3*height, center+0.2*height]
     → Mark as navigable free-space
```

**Parameters:**
- `voxel_size` – Grid cell size (1.5m)
- `empty_threshold` – Max points to consider voxel empty (50)
- `dense_threshold` – Min points for obstacle neighbor (200)
- `min_dense_neighbors` – Min adjacent obstacles required (3)

**Output:** Array of free-space voxel centers

---

### 3. Waypoint Generation (path_planner.py)

**Goal:** Create collision-free navigation waypoints

**Algorithm:**

```
1. Randomly sample candidate points from free-space
2. Build visibility graph:
   - Connect if distance < 15m AND line-of-sight clear
   - Check line at 15 samples along segment
3. Find largest connected component (ensures navigation feasibility)
4. Sort by X-coordinate, select evenly-spaced subset
→ Final waypoints ordered for smooth traversal
```

**Output:** Ordered waypoints (typically 10 waypoints)

---

### 4. Path Smoothing (main.py)

**Goal:** Create smooth, natural camera motion

**Method:** Catmull-Rom cubic spline interpolation

```
For each segment [P_i, P_{i+1}]:
  Generate 30 intermediate points using cubic Catmull-Rom basis
  Result: 300 camera positions from 10 waypoints
```

**Why Catmull-Rom?**
- ✓ Passes through control points (waypoints)
- ✓ C² continuous (smooth acceleration)
- ✓ Natural, non-jerky motion

---

### 5. Camera Rendering (renderer.py)

**Goal:** Render high-quality frames from camera positions

**Rendering pipeline:**

```
For each camera position:
  1. Transform world points to camera space
  2. Project via perspective projection: 
     x_screen = f_x * (x_cam / z_cam) + c_x
  3. Depth-sort (painter's algorithm, far-to-near)
  4. Rasterize points with 2-pixel radius
  5. Save as PNG
→ Assemble frames into MP4 via ffmpeg
```

**Parameters:**
- Resolution: 1920×1080
- FOV: 60°
- Frame rate: 30 fps
- Duration: 10 seconds (300 frames)

---

## Configuration & Tuning

Edit parameters in `main.py`:

```python
# Video parameters
FPS = 30                  # Frames per second
VIDEO_DURATION = 10       # Seconds, 20 was used for submission
W, H = 1920, 1080         # Resolution
FOV_Y = 60                # Field of view (degrees)

# Path planning
voxel_size = 1.5          # Grid cell size (m)
empty_threshold = 50      # Max points in empty voxel
dense_threshold = 200     # Min points for obstacle
```

Edit parameters in `path_planner.py`:

```python
# Waypoint generation
candidate_count = 50      # Initial random candidates
collision_threshold = 100 # Points per voxel for obstruction
n_waypoints = 10          # Final waypoint count
```

---

## Known Limitations

### Current

1. **No mesh reconstruction** – Renders only point clouds (no surfaces)

2. **Fixed viewpoint behavior** – Camera looks forward along path

3. **ffmpeg dependency** – Requires external tool

---

## Troubleshooting

### "ModuleNotFoundError: No module named 'plyfile'"

**Solution:** Reinstall dependencies
```bash
pip install -r requirements.txt --upgrade
```

### "ffmpeg not found" / Video generation fails

**Solution 1 (Windows):** Add ffmpeg to PATH
```bash
# Download from https://ffmpeg.org/download.html
# Extract and add to C:\Program Files\ffmpeg\bin
# Add to system PATH
```

**Solution 2:** Specify custom ffmpeg path in `renderer.py`:
```python
ffmpeg_path = r"C:\Program Files\ffmpeg\bin\ffmpeg.exe"
cmd = [ffmpeg_path, "-y", ...]
```

### "No waypoints found, exiting"

**Causes:**
- Scene too small or dense
- Voxel parameters too restrictive

**Solutions:**
- Increase `candidate_count`
- Decrease `empty_threshold`
- Increase `voxel_size`

### Video is black or garbled

**Causes:**
- Camera outside scene bounds
- Rendering parameters mismatch

**Solutions:**
- Check `focal_x`, `focal_y` (should be ~1000 for 1920px width, 60° FOV)
- Verify scene center calculation

---

## Supported Scene Formats

✓ **PLY** (Stanford PLY format)
- With or without color (uses SH coefficients or RGB)
- Tested with 3D Gaussian Splat outputs

---

## Future Roadmap

See [TECHNICAL_REPORT.md](TECHNICAL_REPORT.md#future-improvements) for detailed vision.

Short-term:
- [ ] Multi-format scene loading (OBJ, glTF)
- [ ] Real-time preview (PyOpenGL viewport)
- [ ] Interactive camera control

Medium-term:
- [ ] GPU-accelerated rendering (CUDA)
- [ ] Advanced path planning (RRT*, PRM)
- [ ] Physics-based obstacle avoidance

Long-term:
- [ ] Photorealistic rendering (ray tracing)
- [ ] Semantic scene understanding
- [ ] Automatic cinematography (key frame generation)

